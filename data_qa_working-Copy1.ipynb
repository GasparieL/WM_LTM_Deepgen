{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6e5a31a-ac21-4f0e-bbbf-ae75df27eed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "# import moss\n",
    "import csv\n",
    "import random\n",
    "%matplotlib inline\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "import os\n",
    "from pandas import Timestamp\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdab13fb-e360-4ce5-a401-f0ce37a54cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = op.abspath('./')\n",
    "\n",
    "data_files = glob.glob(op.join(home_dir,\n",
    "                        'data',\n",
    "                        '*.csv'))\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf4051a1-de29-46b8-9b8c-40a0062e850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'image_recall_response.keys'\n",
    "threshold = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "321ae7cd-fcff-4d0f-91e0-f0b5f77f78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_dates = []\n",
    "for file_path in data_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if column_name in df.columns:\n",
    "            creation_date = df['date']\n",
    "            creation_dates.append(creation_date)\n",
    "    except Exception as e:\n",
    "#             print(f\"Error reading {file_path}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56e13c29-0c12-4868-a53f-c47368a1dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dates(series):\n",
    "    date_str = series.iloc[0]\n",
    "    if \"24h\" in date_str:\n",
    "        corrected_date_str = date_str.replace(\"24h\", \"00h\")\n",
    "        dt = pd.to_datetime(corrected_date_str, format='%Y-%m-%d_%Hh%M.%S.%f')\n",
    "        dt += timedelta(days=1)\n",
    "    else:\n",
    "        dt = pd.to_datetime(date_str, format='%Y-%m-%d_%Hh%M.%S.%f')\n",
    "    return dt\n",
    "\n",
    "dates = [parse_dates(series) for series in creation_dates]\n",
    "\n",
    "min_date = min(dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acea60fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unit_variance(df, col, unit, group=None, suffix=\"_within\"):\n",
    "    \"\"\"Remove variance between sampling units.\n",
    "\n",
    "    This is useful for plotting repeated-measures data using within-unit\n",
    "    error bars.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Input data. Will have a new column added.\n",
    "    col : column name\n",
    "        Column in dataframe with quantitative measure to modify.\n",
    "    unit : column name\n",
    "        Column in dataframe defining sampling units (e.g., subjects).\n",
    "    group : column name(s), optional\n",
    "        Columns defining groups to remove unit variance within.\n",
    "    suffix : string, optional\n",
    "        Suffix appended to ``col`` name to create new column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : DataFrame\n",
    "        Returns modified dataframe.\n",
    "\n",
    "    \"\"\"\n",
    "    new_col = col + suffix\n",
    "\n",
    "    def demean(x):\n",
    "        return x - x.mean()\n",
    "\n",
    "    if group is None:\n",
    "        new = df.groupby(unit)[col].transform(demean)\n",
    "        new += df[col].mean()\n",
    "        df.loc[:, new_col] = new\n",
    "    else:\n",
    "        df.loc[:, new_col] = np.nan\n",
    "        for level, df_level in df.groupby(group):\n",
    "            new = df_level.groupby(unit)[col].transform(demean)\n",
    "            new += df_level[col].mean()\n",
    "            df.loc[new.index, new_col] = new\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "506bf0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_demean(df, list_of_variables):\n",
    "    for l in list_of_variables:\n",
    "        df[l] = df[l] - np.mean(df[l])\n",
    "        z_scored = f\"{l}_z\"\n",
    "        df[z_scored] = scaler.fit_transform(df[[l]])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08608fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_square_and_mean(df, list_of_variables):\n",
    "    for l in list_of_variables:\n",
    "        squared_col = f\"{l}_sq\"\n",
    "        df[squared_col] = df[l]**2\n",
    "        df[squared_col] = df[squared_col] - np.mean(df[squared_col])\n",
    "        z_scored = f\"{squared_col}_z\"\n",
    "        df[z_scored] = scaler.fit_transform(df[[squared_col]])\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fffdc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string(value):\n",
    "    try:\n",
    "        # Check if value is a string and looks like a list\n",
    "        if isinstance(value, str) and value.startswith('[') and value.endswith(']'):\n",
    "            # Remove brackets and split by comma\n",
    "            cleaned = value.strip('[]')\n",
    "            if cleaned:  # Check if the string is not empty\n",
    "                # Convert each part to float and calculate average\n",
    "                numbers = [float(num) for num in cleaned.split(',')]\n",
    "                return sum(numbers) / len(numbers)\n",
    "            else:\n",
    "                return None  # Return None or another placeholder for empty lists\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting value {value}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbb1b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_differences(dataframe):\n",
    "    # Determine attended and unattended values for IT and V2\n",
    "    dataframe['it_sim_dis_attend'] = np.where(dataframe['attend'] == 'img1', dataframe['IT_root_im1'], dataframe['IT_root_im2'])\n",
    "    dataframe['v2_sim_dis_attend'] = np.where(dataframe['attend'] == 'img1', dataframe['V2_root_im1'], dataframe['V2_root_im2'])\n",
    "\n",
    "    dataframe['it_sim_dis_test'] = np.where(dataframe['test_item'] == 'img1', dataframe['IT_root_im1'], dataframe['IT_root_im2'])\n",
    "    dataframe['v2_sim_dis_test'] = np.where(dataframe['test_item'] == 'img1', dataframe['V2_root_im1'], dataframe['V2_root_im2'])\n",
    "\n",
    "    \n",
    "    dataframe['it_sim_dis_unattend'] = np.where(dataframe['attend'] != 'img1', dataframe['IT_root_im1'], dataframe['IT_root_im2'])\n",
    "    dataframe['v2_sim_dis_unattend'] = np.where(dataframe['attend'] != 'img1', dataframe['V2_root_im1'], dataframe['V2_root_im2'])\n",
    "\n",
    "    \n",
    "    dataframe['it_sim_dis_untest'] = np.where(dataframe['test_item'] != 'img1', dataframe['IT_root_im1'], dataframe['IT_root_im2'])\n",
    "    dataframe['v2_sim_dis_untest'] = np.where(dataframe['test_item'] != 'img1', dataframe['V2_root_im1'], dataframe['V2_root_im2'])\n",
    "\n",
    "    # Calculate differences\n",
    "    dataframe['it_sim_dis_diff'] = np.where(dataframe['attend'] == 'img1', dataframe['IT_root_im1'] - dataframe['IT_root_im2'], dataframe['IT_root_im2'] - dataframe['IT_root_im1'])\n",
    "    dataframe['v2_sim_dis_diff'] = np.where(dataframe['attend'] == 'img1', dataframe['V2_root_im1'] - dataframe['V2_root_im2'], dataframe['V2_root_im2'] - dataframe['V2_root_im1'])\n",
    "\n",
    "    dataframe['it_sim_dis_diff_test'] = np.where(dataframe['test_item'] == 'img1', dataframe['IT_root_im1'] - dataframe['IT_root_im2'], dataframe['IT_root_im2'] - dataframe['IT_root_im1'])\n",
    "    dataframe['v2_sim_dis_diff_test'] = np.where(dataframe['test_item'] == 'img1', dataframe['V2_root_im1'] - dataframe['V2_root_im2'], dataframe['V2_root_im2'] - dataframe['V2_root_im1'])\n",
    "\n",
    "    # Determine convergence and preferences\n",
    "    dataframe['v2_converges'] = np.where((dataframe['it_sim_dis_diff'] > 0) & (dataframe['v2_sim_dis_diff'] > 0) | (dataframe['it_sim_dis_diff'] < 0) & (dataframe['v2_sim_dis_diff'] < 0), 'V2/IT agree', 'V2/IT disagree')\n",
    "\n",
    "    dataframe['v2_prefers'] = np.where(dataframe['v2_sim_dis_diff'] > 0, 'Prioritized', 'Deprioritized')\n",
    "    dataframe['it_prefers'] = np.where(dataframe['it_sim_dis_diff'] > 0, 'Prioritized', 'Deprioritized')\n",
    "    \n",
    "    \n",
    "    dataframe['v2_prefers_test'] = np.where(dataframe['v2_sim_dis_diff_test'] > 0, 'Tested', 'Untested')\n",
    "    dataframe['it_prefers_test'] = np.where(dataframe['it_sim_dis_diff_test'] > 0, 'Tested', 'Untested')\n",
    "    \n",
    "    \n",
    "    dataframe['Distractor V2 Similarity Preference Tested'] = dataframe['v2_prefers_test'] \n",
    "    dataframe['Distractor IT Similarity Preference Tested'] = dataframe['it_prefers_test']\n",
    "    \n",
    "    \n",
    "    \n",
    "    dataframe['Distractor V2 Similarity Preference'] = dataframe['v2_prefers'] \n",
    "    dataframe['Distractor IT Similarity Preference'] = dataframe['it_prefers']\n",
    "    \n",
    "    dataframe['it_im1_im2'] = dataframe['IT_im1_im2']\n",
    "    dataframe['v2_im1_im2'] = dataframe['V2_im1_im2']\n",
    "    \n",
    "    dataframe['IT_diff_binned'] = pd.qcut(dataframe['it_sim_dis_diff'], 5, duplicates='drop')\n",
    "    dataframe['V2_diff_binned'] = pd.qcut(dataframe['v2_sim_dis_diff'], 5, duplicates='drop')\n",
    "    \n",
    "    dataframe['IT_diff_binned_test'] = pd.qcut(dataframe['it_sim_dis_diff_test'], 5, duplicates='drop')\n",
    "    dataframe['V2_diff_binned_test'] = pd.qcut(dataframe['v2_sim_dis_diff_test'], 5, duplicates='drop')\n",
    "    \n",
    "    \n",
    "    dataframe = df_demean(dataframe, ['it_sim_dis_diff', 'v2_sim_dis_diff', 'it_sim_dis_attend', 'v2_sim_dis_attend', 'it_sim_dis_unattend', 'v2_sim_dis_unattend', 'it_sim_dis_test', 'v2_sim_dis_test', 'it_sim_dis_untest', 'v2_sim_dis_untest', 'it_sim_dis_diff_test', 'v2_sim_dis_diff_test' ])\n",
    "\n",
    "    dataframe = df_square_and_mean(dataframe, ['it_sim_dis_diff', 'v2_sim_dis_diff', 'it_sim_dis_attend', 'v2_sim_dis_attend', 'it_sim_dis_unattend', 'v2_sim_dis_unattend', 'it_sim_dis_test', 'v2_sim_dis_test', 'it_sim_dis_untest', 'v2_sim_dis_untest', 'it_sim_dis_diff_test', 'v2_sim_dis_diff_test' ])\n",
    "\n",
    "    \n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "396657fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_columns(dataframe, column_params):\n",
    "    \"\"\"\n",
    "    Categorizes specified columns in a DataFrame into discrete categories based on quantiles.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: The DataFrame to process.\n",
    "    - column_params: A dictionary specifying the number of categories and labels for each column prefix.\n",
    "\n",
    "    Returns:\n",
    "    - The modified DataFrame with additional columns for categorized data.\n",
    "    \"\"\"\n",
    "    for label in ['it_sim_dis_attend', 'v2_sim_dis_attend', 'it_sim_dis_unattend', 'v2_sim_dis_unattend', 'it_sim_dis_diff', 'v2_sim_dis_diff', 'it_im1_im2', 'v2_im1_im2', 'it_sim_dis_test', 'v2_sim_dis_test', 'it_sim_dis_untest', 'v2_sim_dis_untest', 'it_sim_dis_diff_test', 'v2_sim_dis_diff_test', 'v2_sim_dis_diff_sq', 'it_sim_dis_diff_sq', 'v2_sim_dis_diff_test_sq','it_sim_dis_diff_test_sq']:\n",
    "        # Determine the column prefix to decide which set of parameters to use\n",
    "        column_prefix = 'v2' if 'v2' in label else 'it'\n",
    "        \n",
    "        # Extract the number of categories and labels from the parameters dictionary\n",
    "        n_cats = column_params[column_prefix]['n_cats']\n",
    "        labels = column_params[column_prefix]['labels']\n",
    "        \n",
    "        # Categorize the column data\n",
    "        dataframe[label + '_cat'] = pd.qcut(dataframe[label], q=n_cats, labels=labels, duplicates='drop')\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50523cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validity_assignment(df):\n",
    "    x = []\n",
    "    for i in df['validity']:\n",
    "        if i == 'valid':\n",
    "            x.append('prioritized')\n",
    "        else:\n",
    "            x.append('deprioritized')\n",
    "\n",
    "    df['Tested Item'] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d15739ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_column_addition(df):\n",
    "    \n",
    "    df['V2 Distractor Similarity\\nto Prioritized Item'] = df['v2_sim_dis_attend_cat']\n",
    "    df['IT Distractor Similarity\\nto Prioritized Item'] = df['it_sim_dis_attend_cat']\n",
    "    df['V2 Distractor Similarity\\nto Deprioritized Item'] = df['v2_sim_dis_unattend_cat']\n",
    "    df['IT Distractor Similarity\\nto Deprioritized Item'] = df['it_sim_dis_unattend_cat']\n",
    "    df['Prioritized - Deprioritized IT Distractor Similarity'] = df['it_sim_dis_diff_cat'] \n",
    "    df['Prioritized - Deprioritized V2 Distractor Similarity'] = df['v2_sim_dis_diff_cat'] \n",
    "    df['Prioritized - Deprioritized IT Distractor Similarity Squared'] = df['v2_sim_dis_diff_sq_cat'] \n",
    "    df['Prioritized - Deprioritized V2 Distractor Similarity Squared'] = df['it_sim_dis_diff_sq_cat'] \n",
    "\n",
    "    \n",
    "    df['V2 Distractor Similarity\\nto Tested Item'] = df['v2_sim_dis_test_cat']\n",
    "    df['IT Distractor Similarity\\nto Tested Item'] = df['it_sim_dis_test_cat']\n",
    "    df['V2 Distractor Similarity\\nto Untested Item'] = df['v2_sim_dis_untest_cat']\n",
    "    df['IT Distractor Similarity\\nto Untested Item'] = df['it_sim_dis_untest_cat']\n",
    "    df['Tested - Untested IT Distractor Similarity'] = df['it_sim_dis_diff_test_cat'] \n",
    "    df['Tested - Untested V2 Distractor Similarity'] = df['v2_sim_dis_diff_test_cat'] \n",
    "    df['Tested - Untested IT Distractor Similarity Squared'] = df['v2_sim_dis_diff_test_sq_cat'] \n",
    "    df['Tested - Untested V2 Distractor Similarity Squared'] = df['it_sim_dis_diff_test_sq_cat'] \n",
    "\n",
    "   \n",
    "    df['IT_diff_binned'] = pd.qcut(df['it_sim_dis_diff'], 5, duplicates='drop')\n",
    "    df['V2_diff_binned'] = pd.qcut(df['v2_sim_dis_diff'], 5, duplicates='drop')\n",
    "    df['IT_diff_binned_sq'] = pd.qcut(df['it_sim_dis_diff_sq'], 5, duplicates='drop')\n",
    "    df['V2_diff_binned_sq'] = pd.qcut(df['v2_sim_dis_diff_sq'], 5, duplicates='drop')\n",
    "\n",
    "\n",
    "    df['IT_diff_binned_test'] = pd.qcut(df['it_sim_dis_diff_test'], 5, duplicates='drop')\n",
    "    df['V2_diff_binned_test'] = pd.qcut(df['v2_sim_dis_diff_test'], 5, duplicates='drop')\n",
    "    df['IT_diff_binned_test_sq'] = pd.qcut(df['it_sim_dis_diff_test_sq'], 5, duplicates='drop')\n",
    "    df['V2_diff_binned_test_sq'] = pd.qcut(df['v2_sim_dis_diff_test_sq'], 5, duplicates='drop')\n",
    "\n",
    "    def round_to_significant_figures(x, sig_figs=2):\n",
    "        if x == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return round(x, sig_figs - int(np.floor(np.log10(abs(x)))) - 1)\n",
    "\n",
    "\n",
    "    def process_interval(interval):\n",
    "        # Round both bounds\n",
    "        lower_rounded = round_to_significant_figures(interval.left)\n",
    "        upper_rounded = round_to_significant_figures(interval.right)\n",
    "        # Return a new interval with the rounded bounds\n",
    "        return pd.Interval(lower_rounded, upper_rounded)\n",
    "\n",
    "    df['IT_diff_binned'] = df['IT_diff_binned'].apply(process_interval)\n",
    "    df['V2_diff_binned'] = df['V2_diff_binned'].apply(process_interval)\n",
    "    df['IT_diff_binned_sq'] = df['IT_diff_binned_sq'].apply(process_interval)\n",
    "    df['V2_diff_binned_sq'] = df['V2_diff_binned_sq'].apply(process_interval)\n",
    "\n",
    "    df['IT_diff_binned_test'] = df['IT_diff_binned_test'].apply(process_interval)\n",
    "    df['V2_diff_binned_test'] = df['V2_diff_binned_test'].apply(process_interval)\n",
    "    df['IT_diff_binned_test_sq'] = df['IT_diff_binned_test_sq'].apply(process_interval)\n",
    "    df['V2_diff_binned_test_sq'] = df['V2_diff_binned_test_sq'].apply(process_interval)\n",
    "\n",
    "    df['Prioritized - Deprioritized V2 Distractor Similarity Ranges'] = df['V2_diff_binned']\n",
    "    df['Prioritized - Deprioritized IT Distractor Similarity Ranges'] = df['IT_diff_binned']\n",
    "    df['Prioritized - Deprioritized V2 Distractor Similarity Squared Ranges'] = df['V2_diff_binned_sq']\n",
    "    df['Prioritized - Deprioritized IT Distractor Similarity Squared Ranges'] = df['IT_diff_binned_sq']\n",
    "\n",
    "    df['Tested - Untested V2 Distractor Similarity Ranges'] = df['V2_diff_binned_test']\n",
    "    df['Tested - Untested IT Distractor Similarity Ranges'] = df['IT_diff_binned_test']\n",
    "    df['Tested - Untested V2 Distractor Similarity Squared Ranges'] = df['V2_diff_binned_test_sq']\n",
    "    df['Tested - Untested IT Distractor Similarity Squared Ranges'] = df['IT_diff_binned_test_sq']\n",
    "    \n",
    "    \n",
    "    df['tested_item'] = df['Tested Item']\n",
    "    df['ret_rel'] = df['Retrocue Reliability']\n",
    "    \n",
    "    df['validity_binary'] = df['Tested Item'].apply(lambda x: 1 if x == 'prioritized' else 0)\n",
    "    df['reliability_binary'] = df['Retrocue Reliability'].apply(lambda x: 1 if x == 'high' else 0)\n",
    "    df['validity_binary_z'] = scaler.fit_transform(df[['validity_binary']])\n",
    "    df['reliability_binary_z'] = scaler.fit_transform(df[['reliability_binary']])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    df['V2 Distractor Similarity to Tested Item'] = df['v2_sim_dis_test_z']\n",
    "    df['IT Distractor Similarity to Tested Item'] = df['it_sim_dis_test_z']\n",
    "    df['Tested - Untested V2 Distractor Similarity'] = df['v2_sim_dis_diff_test_z']\n",
    "    df['Tested - Untested IT Distractor Similarity'] = df['it_sim_dis_diff_test_z']\n",
    "\n",
    "\n",
    "    df['V2 Distractor Similarity\\nto Prioritized Item'] = df['v2_sim_dis_attend_z']\n",
    "    df['IT Distractor Similarity\\nto Prioritized Item'] = df['it_sim_dis_attend_z']\n",
    "    df['V2 Distractor Similarity\\nto Deprioritized Item'] = df['v2_sim_dis_unattend_z']\n",
    "    df['IT Distractor Similarity\\nto Deprioritized Item'] = df['it_sim_dis_unattend_z']\n",
    "\n",
    "    df['Prioritized - Deprioritized IT Distractor Similarity'] = df['it_sim_dis_diff_z'] \n",
    "    df['Prioritized - Deprioritized V2 Distractor Similarity'] = df['v2_sim_dis_diff_z'] \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71094d4f-127f-4596-976e-4f04382ab7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_creation(data_files, start_date, end_date):\n",
    "    processed_dfs = []\n",
    "    date_column = 'date'\n",
    "\n",
    "    for file_path in data_files:\n",
    "        try:\n",
    "            # Read the CSV file and append to the list of DataFrames\n",
    "            temp_df = pd.read_csv(file_path)\n",
    "            temp_df['filename'] = file_path\n",
    "            processed_dfs.append(temp_df)\n",
    "        except Exception as e:\n",
    "            # Optionally, print or log the error\n",
    "#             print(f\"Failed to read {file_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if processed_dfs:\n",
    "        df = pd.concat(processed_dfs, ignore_index=True)\n",
    "        df[date_column] = pd.to_datetime(df[date_column], format='%Y-%m-%d_%Hh%M.%S.%f', errors='coerce')\n",
    "        df.dropna(subset=[date_column], inplace=True)\n",
    "        df = df[(df[date_column] >= pd.to_datetime(start_date)) & (df[date_column] <= pd.to_datetime(end_date))]\n",
    "        \n",
    "        # # Uncomment and adapt the following lines as needed:\n",
    "        df = df.loc[df['V2_diff'].notnull()].reset_index(drop=True)\n",
    "        df['reliability'] = df['reliability'].astype(float)\n",
    "        df['Retrocue Reliability'] = np.where(df['reliability'] > 0.75, 'high', 'low')\n",
    "        non_numeric_values = df['resp_correct'][~df['resp_correct'].apply(np.isreal)]\n",
    "        numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "        result = df[numeric_columns].groupby('participant').mean()\n",
    "        \n",
    "        \n",
    "\n",
    "    else:\n",
    "        # Return an empty DataFrame if no files were processed successfully\n",
    "        df = pd.DataFrame()\n",
    "    \n",
    "    return df, numeric_columns\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2990e2ed-2c9e-4df2-8f21-1f563cf0d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, numeric_columns = df_creation(data_files,'2024-10-30', '2024-11-22')\n",
    "### pilot5 '2024-10-08', '2024-10-30'\n",
    "### pilot6 '2024-11-22', '2025-01-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9c3fa5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pilot_number'] = np.where(df['date'] <= '2024-10-31', 1, 2)\n",
    "df_1 = df[df['pilot_number'] == 1]\n",
    "df_2 = df[df['pilot_number'] == 2]\n",
    "\n",
    "len(set(df_1['participant'])), len(set(df_2['participant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecafcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trial_info(df, participant_col, trials_per_batch=30):\n",
    "    \n",
    "    df['Trial_Number'] = df.groupby(participant_col).cumcount() + 1\n",
    "    \n",
    "    df['Trial_Batch'] = ((df['Trial_Number'] - 1) // trials_per_batch) + 1\n",
    "    \n",
    "    return df\n",
    "\n",
    "add_trial_info(df, participant_col='participant')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da395ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial_182 = df[df['trial'] == 182]\n",
    "df_trial_182 = df_trial_182[['participant', 'trial', 'cond_file', 'root', 'IT_diff']]\n",
    "df_trial_182['conditions_batch'] = df_trial_182.groupby(['cond_file', 'root', 'IT_diff']).ngroup() + 1\n",
    "\n",
    "batch_info = df_trial_182.groupby('conditions_batch')['participant'].agg(\n",
    "    participants_count='nunique',  # Count of unique participants\n",
    "    participants_list='unique'  # List of participants in the batch\n",
    ").reset_index()\n",
    "\n",
    "df_trial_182 = df_trial_182.merge(batch_info, on='conditions_batch', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c64ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_trial_182[['participant', 'conditions_batch', 'participants_count', 'participants_list']], \n",
    "                     on='participant', \n",
    "                     how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824bd9f9-4a3e-4f07-8b93-83e979041b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32938ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_params = {\n",
    "    'v2': {'n_cats': 5, 'labels': ['Least Similar', '', '  ', '   ', 'Most Similar']},\n",
    "    'it': {'n_cats': 5, 'labels': ['Least Similar', '', '  ', '   ', 'Most Similar']}\n",
    "}\n",
    "column_name = 'image_recall_response.keys'\n",
    "threshold = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304fe6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3caebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "validity_assignment(df)\n",
    "df = calculate_differences(df)\n",
    "df = categorize_columns(df, column_params)\n",
    "df_column_addition(df)\n",
    "# label_addition(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0cf661",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reliability_binary'] = (df['reliability'] > 0.7).astype(int)\n",
    "df['validity_binary'] = (df['validity'] == 'valid').astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc5bf81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0176ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9adaf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_values_time(value):\n",
    "    try:\n",
    "        # Strip square brackets and split by comma, filtering out empty values\n",
    "        if isinstance(value, str) and value.startswith('[') and value.endswith(']'):\n",
    "            cleaned = value.strip('[]').split(',')\n",
    "            if cleaned == ['']:  # Check if the list after stripping is empty\n",
    "                return None\n",
    "            numbers = [float(num) for num in cleaned if num.strip()]\n",
    "            return numbers\n",
    "        return None\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def process_values_click(value):\n",
    "    try:\n",
    "        # Strip square brackets and split by comma, filtering out empty values\n",
    "        if isinstance(value, str) and value.startswith('[') and value.endswith(']'):\n",
    "            cleaned = value.strip('[]').split(',')\n",
    "            if cleaned == ['']:  # Check if the list after stripping is empty\n",
    "                return None\n",
    "            numbers = [num for num in cleaned if num.strip()]\n",
    "            return numbers\n",
    "        return None\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "    \n",
    "df['processed_mouse.time'] = df['mouse.time'].apply(process_values_time)\n",
    "df['processed_mouse.click'] = df['mouse.clicked_name'].apply(process_values_click)\n",
    "\n",
    "def get_latest_value(entry):\n",
    "    if isinstance(entry, list) and len(entry) > 1:\n",
    "        return [entry[-1]]  # Return a list with the latest value\n",
    "    return entry  # Return unchanged if not a list or list is empty/single element\n",
    "\n",
    "df['processed_mouse.time'] = df['processed_mouse.time'].apply(get_latest_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ebf355",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# Find the earliest date for each participant\n",
    "earliest_dates = df.groupby('participant')['date'].min().reset_index()\n",
    "\n",
    "df = pd.merge(df, earliest_dates, on=['participant', 'date'])\n",
    "\n",
    "\n",
    "\n",
    "participant_summary = df.groupby('participant').agg(\n",
    "    total_entries=pd.NamedAgg(column='participant', aggfunc='size')\n",
    ").reset_index()\n",
    "\n",
    "participant_file_counts = df.groupby(['participant', 'filename']).agg(\n",
    "    entry_count=pd.NamedAgg(column='participant', aggfunc='size'),\n",
    "    \n",
    "    none_mouse=pd.NamedAgg(column='processed_mouse.time', aggfunc=lambda x: x.isna().sum())\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "\n",
    "files_with_high_none_mouse = participant_file_counts[participant_file_counts['none_mouse'] > 100]\n",
    "\n",
    "df_cleaned = df[~df.set_index(['participant', 'filename']).index.isin(files_with_high_none_mouse.set_index(['participant', 'filename']).index)]\n",
    "\n",
    "participant_file_counts_cleaned = df_cleaned.groupby(['participant', 'filename']).agg(\n",
    "    entry_count=pd.NamedAgg(column='participant', aggfunc='size')\n",
    ").reset_index()\n",
    "\n",
    "files_with_low_entries = participant_file_counts_cleaned[participant_file_counts_cleaned['entry_count'] < 200]\n",
    "\n",
    "df_cleaned = df_cleaned[~df_cleaned.set_index(['participant', 'filename']).index.isin(files_with_low_entries.set_index(['participant', 'filename']).index)]\n",
    "\n",
    "cleaned_participant_summary = df_cleaned.groupby('participant').agg(\n",
    "    total_entries=pd.NamedAgg(column='participant', aggfunc='size')\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "none_mouse_summary = df_cleaned.groupby('participant').agg(\n",
    "    none_mouse=pd.NamedAgg(column='processed_mouse.time', aggfunc=lambda x: x.isna().sum())\n",
    ").reset_index()\n",
    "\n",
    "df = df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff05e266",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_participants = df.groupby('participant')['filename'].nunique().reset_index()\n",
    "duplicate_participants = duplicate_participants[duplicate_participants['filename'] > 1]\n",
    "\n",
    "if not duplicate_participants.empty:\n",
    "    print(\"\\nParticipants associated with more than one file:\")\n",
    "    print(duplicate_participants)\n",
    "else:\n",
    "    print(\"\\nNo participants associated with more than one file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba786cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_mouse_summary = df.groupby('participant').agg(\n",
    "    none_mouse=pd.NamedAgg(column='processed_mouse.time', aggfunc=lambda x: x.isna().sum())\n",
    ").reset_index()\n",
    "\n",
    "# Check for participants with none_mouse more than 2/3 of total_entries\n",
    "none_mouse_summary = none_mouse_summary.merge(cleaned_participant_summary, on='participant')\n",
    "none_mouse_summary['ratio'] = none_mouse_summary['none_mouse'] / none_mouse_summary['total_entries']\n",
    "participants_high_none_mouse = none_mouse_summary[none_mouse_summary['ratio'] > (2/3)]\n",
    "\n",
    "# Print the results\n",
    "print(\"Remaining participants with more than 300 entries:\")\n",
    "# print(cleaned_participant_summary)\n",
    "\n",
    "print(\"\\nNone mouse summary for each participant:\")\n",
    "# print(none_mouse_summary)\n",
    "\n",
    "if not participants_high_none_mouse.empty:\n",
    "    print(\"\\nParticipants with none_mouse more than 2/3 of total entries:\")\n",
    "#     print(participants_high_none_mouse)\n",
    "else:\n",
    "    print(\"\\nNo participants have none_mouse more than 2/3 of total entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50417ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_counts = df['participant'].value_counts()\n",
    "participants_less_than_300 = participant_counts[participant_counts < 300]\n",
    "participants_less_than_300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf53b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_length_column(df, column_name):\n",
    "    if column_name in df.columns:\n",
    "        # Clean and convert the values in the specified column\n",
    "        def clean_and_get_length(value):\n",
    "            if isinstance(value, str) and value.startswith('[') and value.endswith(']'):\n",
    "                cleaned = value.strip('[]').split(',')\n",
    "                return len(cleaned)\n",
    "            elif isinstance(value, list):\n",
    "                return 0\n",
    "            else:\n",
    "                return 0  # Handle unexpected data types\n",
    "\n",
    "        # Apply the cleaning and length calculation\n",
    "        df.loc[:, column_name + '_length'] = df[column_name].apply(clean_and_get_length)\n",
    "    else:\n",
    "        print(f\"Column '{column_name}' not found in DataFrame.\")\n",
    "    return df\n",
    "\n",
    "def add_nthresp_column(df, column_name, n):\n",
    "    if column_name in df.columns:\n",
    "        # Clean and convert the values in the specified column\n",
    "        def clean_and_get_nthresp(value):\n",
    "            if isinstance(value, str) and value.startswith('[') and value.endswith(']'):\n",
    "                cleaned = value.strip('[]').split(',')\n",
    "                return cleaned[n]\n",
    "            elif isinstance(value, list):\n",
    "                return \n",
    "            else:\n",
    "                return  # Handle unexpected data types\n",
    "\n",
    "        # Apply the cleaning and length calculation\n",
    "        if n == 0:\n",
    "            temp_str = '_first'\n",
    "        elif n == -1:\n",
    "            temp_str = '_last'\n",
    "        df.loc[:, column_name + temp_str] = df[column_name].apply(clean_and_get_nthresp)\n",
    "    else:\n",
    "        print(f\"Column '{column_name}' not found in DataFrame.\")\n",
    "    return df\n",
    "\n",
    "add_length_column(df, 'mouse.time')\n",
    "add_nthresp_column(df, 'mouse.time', 0)\n",
    "add_nthresp_column(df, 'mouse.time', -1)\n",
    "add_nthresp_column(df, 'mouse.clicked_name', 0)\n",
    "add_nthresp_column(df, 'mouse.clicked_name', -1)\n",
    "\n",
    "# long_instances = df[df['mouse.time_length'] > 1]\n",
    "# print(long_instances)\n",
    "# unique_mouse_time_length_values = df['mouse.time_length'].unique()\n",
    "# unique_mouse_time_length_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660bbb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'participant' in df.columns and not df['participant'].isnull().all():\n",
    "    print(\"'participant' column exists and has values.\")\n",
    "else:\n",
    "    raise KeyError(\"The 'participant' column is missing or has no values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1299b058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe_from_nonresp(df):\n",
    "    # Convert the column entries from string lists to actual lists of floats, or None for empty lists\n",
    "\n",
    "    # Define a mask to filter out rows where the list is empty or any number is out of the specified range\n",
    "    def filter_ranges(numbers):\n",
    "        if numbers is None:\n",
    "            return False\n",
    "        return all(num for num in numbers)\n",
    "    df = df[df['processed_mouse.time'].apply(filter_ranges)]\n",
    "    df = df[df['processed_mouse.click'].apply(filter_ranges)]\n",
    "    # Apply the mask\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966604bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_with_threshold(df, numeric_columns, threshold):\n",
    "    sub_df = df[numeric_columns].groupby('participant').mean().reset_index()\n",
    "    above04_subs = sub_df.loc[sub_df['resp_correct'] >= threshold, 'participant']\n",
    "    df_ret = pd.DataFrame()\n",
    "    for s in above04_subs:\n",
    "        df_ret = pd.concat([df_ret, df.loc[df['participant'] == s]])\n",
    "    df_ret = remove_unit_variance(df_ret,'resp_correct','participant')\n",
    "    df_ret['Accuracy'] = df_ret['resp_correct_within']\n",
    "    return df_ret\n",
    "\n",
    "df = df_with_threshold(df, numeric_columns, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f62a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonresp = clean_dataframe_from_nonresp(df)\n",
    "\n",
    "participant_counts = df_nonresp['participant'].value_counts()\n",
    "participant_counts_df = participant_counts.reset_index()\n",
    "participant_counts_df.columns = ['participant', 'count']\n",
    "\n",
    "print(min(participant_counts_df['count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf6403",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cd6923",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mouse.time_last'] = pd.to_numeric(df['mouse.time_last'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79125bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_unit_variance(df,'mouse.time_last','participant')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334a195c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['analysis_rt'] = df['mouse.time_last_within']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a28baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3273bb59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5c1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_table = defaultdict(int)\n",
    "df_table_totals = defaultdict(int)\n",
    "\n",
    "def update_count(row):\n",
    "    if row['test_item'] == 'img1':\n",
    "        df_table_totals[row['img1']] += 1\n",
    "        if row['resp_correct'] == 1.0:\n",
    "            df_table[row['img1']] += 1\n",
    "    elif row['test_item'] == 'img2':\n",
    "        df_table_totals[row['img2']] += 1\n",
    "        if row['resp_correct'] == 1.0:\n",
    "            df_table[row['img2']] += 1\n",
    "        \n",
    "df.apply(update_count, axis=1)\n",
    "df_table = dict(df_table)\n",
    "\n",
    "\n",
    "df_table_fraction = defaultdict(int)\n",
    "\n",
    "for d in df_table.keys():\n",
    "    df_table_fraction[d] = df_table[d]/df_table_totals[d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(df['img1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fd4037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_table_fraction[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d81816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['attended_memorability'] = np.where(df['attend'] == 'img1', df_table_fraction[str(df['img1'])], df_table_fraction[str(df['img2'])])\n",
    "# df['unattended_memorability'] = np.where(df['attend'] == 'img2', df_table_fraction[str(df['img2'])], df_table_fraction[str(df['img1'])])\n",
    "\n",
    "# df['tested_memorability'] = np.where(df['test_item'] == 'img1', df_table_fraction[str(df['img1'])], df_table_fraction[str(df['img2'])])\n",
    "# df['untested_memorability'] = np.where(df['test_item'] == 'img2', df_table_fraction[str(df['img2'])], df_table_fraction[str(df['img1'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['tested_memorability'] = df['test_item'].map(lambda x: df_table_fraction[str(df['img1'])] if x == 'img1' else df_table_fraction[str(df['img2'])])\n",
    "# df['untested_memorability'] = df['test_item'].map(lambda x: df_table_fraction[str(df['img2'])] if x == 'img1' else df_table_fraction[str(df['img1'])])\n",
    "\n",
    "\n",
    "# df['attended_memorability'] = df['attend'].map(lambda x: df_table_fraction[str(df['img1'])] if x == 'img1' else df_table_fraction[str(df['img2'])])\n",
    "# df['unattended_memorability'] = df['attend'].map(lambda x: df_table_fraction[str(df['img2'])] if x == 'img1' else df_table_fraction[str(df['img1'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9826da36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tested_memorability'] = np.where(\n",
    "    df['test_item'] == 'img1',\n",
    "    df['img1'].astype(str).map(df_table_fraction),\n",
    "    df['img2'].astype(str).map(df_table_fraction)\n",
    ")\n",
    "\n",
    "df['untested_memorability'] = np.where(\n",
    "    df['test_item'] == 'img1',\n",
    "    df['img2'].astype(str).map(df_table_fraction),\n",
    "    df['img1'].astype(str).map(df_table_fraction)\n",
    ")\n",
    "\n",
    "df['attended_memorability'] = np.where(\n",
    "    df['attend'] == 'img1',\n",
    "    df['img1'].astype(str).map(df_table_fraction),\n",
    "    df['img2'].astype(str).map(df_table_fraction)\n",
    ")\n",
    "\n",
    "df['unattended_memorability'] = np.where(\n",
    "    df['attend'] == 'img1',\n",
    "    df['img2'].astype(str).map(df_table_fraction),\n",
    "    df['img1'].astype(str).map(df_table_fraction)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5693a65d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad46bd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_memorability = pd.read_csv('predictions_pilot5.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f976fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_memorability['filename'] = df_memorability['filename'].str.replace('new_stimuli', 'stimuli')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31211a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_memorability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c7c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memorability_dict = dict(zip(df_memorability['filename'], df_memorability['predictions']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f638b7d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# memorability_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be03d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['tested_memorability_resmem'] = np.where(\n",
    "#     df['test_item'] == 'img1',\n",
    "#     df['img1'].astype(str).map(memorability_dict),\n",
    "#     df['img2'].astype(str).map(memorability_dict)\n",
    "# )\n",
    "\n",
    "# df['untested_memorability_resmem'] = np.where(\n",
    "#     df['test_item'] == 'img1',\n",
    "#     df['img2'].astype(str).map(memorability_dict),\n",
    "#     df['img1'].astype(str).map(memorability_dict)\n",
    "# )\n",
    "\n",
    "# df['attended_memorability_resmem'] = np.where(\n",
    "#     df['attend'] == 'img1',\n",
    "#     df['img1'].astype(str).map(memorability_dict),\n",
    "#     df['img2'].astype(str).map(memorability_dict)\n",
    "# )\n",
    "\n",
    "# df['unattended_memorability_resmem'] = np.where(\n",
    "#     df['attend'] == 'img1',\n",
    "#     df['img2'].astype(str).map(memorability_dict),\n",
    "#     df['img1'].astype(str).map(memorability_dict)\n",
    "# )\n",
    "\n",
    "\n",
    "# df['distractor_memorability'] = df['ping_img'].astype(str).map(memorability_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492bc754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pilot_number'] = np.where(df['date'] <= '2024-10-31', 1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac52e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df[df['pilot_number'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df_1['participant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc7f7bf-f053-4d32-91aa-6d98301e3856",
   "metadata": {},
   "source": [
    "<!-- # df['tested_memorability_resmem_z'] = scaler.fit_transform(df[['tested_memorability_resmem']]) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24559fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['it_pos_neg'] =  np.where(df['it_sim_dis_diff_test_z'] <= 0, 0, 1)\n",
    "df['v2_pos_neg'] =  np.where(df['v2_sim_dis_diff_test_z'] <= 0, 0, 1)\n",
    "df['it_pos_neg_abs'] =  np.where(df['it_sim_dis_test_z'] <= 0, 0, 1)\n",
    "df['v2_pos_neg_abs'] =  np.where(df['v2_sim_dis_test_z'] <= 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08285f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rt'] = df['mouse.time_last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad96700",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df['participant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b028e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['it_pos_neg_u'] =  np.where(df['it_sim_dis_diff_test'] <= 0, 0, 1)\n",
    "df['v2_pos_neg_u'] =  np.where(df['v2_sim_dis_diff_test'] <= 0, 0, 1)\n",
    "df['it_pos_neg_abs_u'] =  np.where(df['it_sim_dis_test'] <= 0, 0, 1)\n",
    "df['v2_pos_neg_abs_u'] =  np.where(df['v2_sim_dis_test'] <= 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['it_sim_dis_diff_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c71694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['it_sim_dis_diff_test_z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26800555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.read_csv('pilot5_TEST.csv')\n",
    "# df2 = pd.read_csv('pilot6_TEST.csv')\n",
    "\n",
    "# Concatenate the dataframes\n",
    "# combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Save to a new CSV if needed\n",
    "# df.to_csv('pilot_TOTAL_TEST_edits.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c343cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_1 = combined_df[combined_df['pilot_number'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f11feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa24c3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f883b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# con = sqlite3.connect(\"pilot5_TEST.csv\")\n",
    "# cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25621e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
